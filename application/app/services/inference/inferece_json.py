import time

from datetime import datetime
from multiprocessing import Queue, Event

from queue import Empty
from tkinter import filedialog, messagebox
import os
import json
from collections import deque

import app.core.globals as g_vars
from app.services.inference.macro_dectector import MacroDetector

def main(stop_event=None, log_queue:Queue=None, chart_Show=True):
    use_existing = False
    if g_vars.init_model_path and g_vars.init_scale_path:
        if os.path.exists(g_vars.init_model_path) and os.path.exists(g_vars.init_scale_path):
            model_name = os.path.basename(g_vars.init_model_path)
            msg = f"ì´ì „ì— ì‚¬ìš©í•œ ëª¨ë¸ì„ ë‹¤ì‹œ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\n\nëª¨ë¸: {model_name}"
            use_existing = messagebox.askyesno("ê²½ë¡œ ì¬ì‚¬ìš©", msg)
        else:
            if log_queue: log_queue.put("âš ï¸ ì´ì „ ëª¨ë¸ íŒŒì¼ì´ ê²½ë¡œì— ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ì„ íƒí•©ë‹ˆë‹¤.")

    # 2. 'ì•„ë‹ˆì˜¤'ë¥¼ ëˆŒë €ê±°ë‚˜ ê¸°ì¡´ ê²½ë¡œê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒˆë¡œ ì„ íƒ
    if not use_existing:
        initial_dir = g_vars.scaler_path
        
        # (1) ëª¨ë¸ ì„ íƒ
        new_model_path = filedialog.askopenfilename(
            initialdir=initial_dir,
            title="[1/2] í•™ìŠµëœ ëª¨ë¸(.pt) íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            filetypes=(("PyTorch ëª¨ë¸", "*.pt"), ("ëª¨ë“  íŒŒì¼", "*.*"))
        )
        if not new_model_path:
            if log_queue: log_queue.put("âŒ ëª¨ë¸ ì„ íƒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        g_vars.init_model_path = new_model_path

        # (2) ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒ
        new_scale_path = filedialog.askopenfilename(
            initialdir=initial_dir,
            title="[2/2] í•´ë‹¹ ëª¨ë¸ì˜ ìŠ¤ì¼€ì¼ëŸ¬(.pkl) íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            filetypes=(("ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼", "*.pkl"), ("ëª¨ë“  íŒŒì¼", "*.*"))
        )
        if not new_scale_path:
            if log_queue: log_queue.put("âŒ ìŠ¤ì¼€ì¼ëŸ¬ ì„ íƒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
        g_vars.init_scale_path = new_scale_path

    # 3. ìµœì¢… ê²½ë¡œ í™•ì • ë¡œê·¸ (ì´ ë¶€ë¶„ì„ g_vars ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ì •!)
    if log_queue:
        # local variable ëŒ€ì‹  g_vars ê°’ì„ ì°¸ì¡°í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
        m_name = os.path.basename(g_vars.init_model_path)
        s_name = os.path.basename(g_vars.init_scale_path)
        log_queue.put(f"ğŸ“‚ ë¡œë“œ ì™„ë£Œ:\n- ëª¨ë¸: {m_name}\n- ìŠ¤ì¼€ì¼ëŸ¬: {s_name}")

    # Detector ì´ˆê¸°í™”
    detector = MacroDetector(
        model_path=g_vars.init_model_path,
        seq_len=g_vars.SEQ_LEN,
        threshold=g_vars.threshold,
        chart_Show=chart_Show,
        stop_event=stop_event,
        scale_path=g_vars.init_scale_path,
        log_queue=log_queue
    )

    if g_vars.INFERENCE_CHART_VIEW.value == False:
        with g_vars.PROCESS_LOCK:
            g_vars.INFERENCE_CHART_VIEW.value = True

        if log_queue:
            log_queue.put(f"âœ… ì°¨íŠ¸ í™œì„±í™” ìƒíƒœ, ë¹„êµ ë¶„ì„ ëª¨ë“œë¡œ ì§„í•´ë©ë‹ˆë‹¤.")
        else:
            print(f"âœ… ì°¨íŠ¸ í™œì„±í™” ìƒíƒœ, ë¹„êµ ë¶„ì„ ëª¨ë“œë¡œ ì§„í•´ë©ë‹ˆë‹¤.")
        detector.start_plot_process()
        
    while True:
        if stop_event is None:
            stop_event = Event()

        if log_queue : log_queue.put(f"weight_threshold : {g_vars.weight_threshold}")
        else:
            print(f"weight_threshold : {g_vars.weight_threshold}")
            
        user_data:list[dict]

        file_pahh = filedialog.askopenfilename(title="Json íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”", filetypes=(("json íŒŒì¼", "*.json"), ("ëª¨ë“  íŒŒì¼", "*.*")))
        if not os.path.exists(file_pahh):
            return [] 

        try:
            with open(file_pahh, "r", encoding="utf-8") as f:
                data = json.load(f)
        
            user_data = data
        except Exception as e:
            print(e)
            user_data = []

        print(f"user_data length : {len(user_data)}")

        detector.buffer = deque(maxlen=int(len(user_data)))

        timeinterval = 7

        if g_vars.INFERENCE_CHART_VIEW.value == False:
            while timeinterval != 0:
                timeinterval -= 1
                if log_queue:
                    log_queue.put(f"inference ì‹œì‘ê¹Œì§€ count : {timeinterval}")
                else:
                    print(f"inference ì‹œì‘ê¹Œì§€ count : {timeinterval}")

                time.sleep(1)

        if log_queue:
            log_queue.put("ğŸŸ¢ Macro Detector Running")
        else:
            print("ğŸŸ¢ Macro Detector Running")

        g_vars.CHART_DATA.put_nowait("NEW_SESSION")

        try:
            for step in user_data:
                data = {
                    'timestamp': datetime.fromisoformat(step.get("timestamp")),
                    'x': step.get("x"),
                    'y': step.get("y"),
                    'deltatime': step.get("deltatime")  
                }
                detector.push(data)
            
            detector._infer()
        finally:
            detector.buffer.clear()
            try:
                while True:
                    g_vars.CHART_DATA.get_nowait()
            except Empty:
                pass

        user_input = "n"
        user_check = True
        for retry in range(5):
            user_input = input("ì¶”ê°€ ì§„í–‰ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip()
            if user_input not in ['y', 'n']:
                print(f"ì˜ëª» ì…ë ¥í•˜ì…¨ìŠµë‹ˆë‹¤. ì¬ì‹œë„ {retry} / 5")
            else:
                user_check = True
                break
            
            user_check = False
        
        if user_check == False:
            return
        
        if user_input == "n":
            return